{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WMfBf10kpOin"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"YkzSjUUwpOiq"},"source":["# Ensemble Learning: La sabiduría de la multitud."]},{"cell_type":"markdown","metadata":{"id":"gEQp2zG6pOiu"},"source":["## Introducción"]},{"cell_type":"markdown","metadata":{"id":"7w0F4MDYpOiu"},"source":["Seguramente ha visto el siguiente experimento en algún documental de televisión: En un frasco grande se han introducido muchos objetos pequeños, por ejemplo caramelos, de tal manera que sea imposible contarlos \"a ojo\", luego se pide a muchas personas que estimen visualmente cuántos caramelos hay en el frasco. Las estimaciones de las personas suelen ser muy disímiles algunas estiman sólo centenas de caramelos y otras decenas de miles de caramelos; cada una de las estimaciones suele estar bastante alejada de la cantidad real de caramelos que hay en el frasco. Hasta aquí nada sorprendente, pero en un momento el presentador sugiere **promediar** las estimaciones dadas por todos los participantes y ... sorpresa, dicho promedio suele ser muy cercano a la cantidad real de caramelos que hay en el frasco!   \n","\n","Lo invito a que vea el siguiente video https://youtu.be/od9MGUNjBVw al respecto.\n","\n","Este experimento no es un truco televisivo, es real y se denomina \"Sabiduría de la Multitud\". Aunque las estimaciones individuales son bastante malas, al **ensamblar** todos los pronósticos individuales, por ejemplo calculando el promedio se suele obtener un resultado que es mejor que cualquier pronóstico individual!  Los errores que cometen los que subestiman la cantidad real se compensan con los errores de quienes sobreestiman dicha cantidad. \n","\n","> La clave en el experimento anterior es que **muchas** personas, lo **más distintas** posibles den su pronóstico.\n","\n","El experimento puede adaptarse perfectamente a nuestros modelos de aprendizaje automático, la idea básica es entrenar varios modelos y luego, si es un problema de Regresión promediar sus pronósticos y si es un problema de Clasificación establecer un sistema de votación entre ellos. Los resultados del ensamblado suelen superar a los de cualquiera de los estimadores individuales.\n","\n","Los ensamblados suelen ser los modelos que ganan en las competencias tipo Kaggle o el famosísimo Netflix Prize Competition y otras. Como desventaja podemos mencionar que, obviamente, consumen muchos más recursos computacionales que los métodos individuales.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"s_dQjXqFpOiw"},"source":["## Ensemble para Problemas de Clasificación"]},{"cell_type":"markdown","metadata":{"id":"VLhnZPxzpOiw"},"source":["Como comentábamos, para problemas de clasificación la idea es entrenar varios algoritmos, cuanto más sean en cantidad y diversidad, mejor y luego establecere agún tipo de votación.  \n","\n","Se suelen utilizar dos mecanismos de votación, **hard voting** y **soft voting**.  \n","\n","- **Hard Voting**: simplemente se asigna la clase que pronosticó la mayoría de los estimadores.   \n","\n","- **Soft Voting**: en este caso es necesario que los estimadores utilizados pueden pronosticar **probabilidades**, como por ejemplo Regresión Logística y sus derivados, hablando en la jerga de Scikit - Learn, que nos ofrezcan predict_proba como resultado. En este caso se promedian las probabilidades pronosticadas para cada clase y se elige la clase que obtuvo el mayor valor promedio entre todos los modelos.   \n","\n","> **Soft Voting suele dar mejores resultados que Hard Voting**\n","\n","\n","Afortunadamente todo esto se hace muy fácilmente con Scikit-Learn!"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-10-29T13:40:51.738152Z","start_time":"2020-10-29T13:40:51.735134Z"},"id":"Gh0QMS1CpOix"},"source":["### VotingClassifier: Implementación en Scikit-Learn"]},{"cell_type":"markdown","metadata":{"id":"bbZxSQNipOiy"},"source":["Para instrumentar el mecanismo de votación Sci-kit Learn nos brinda\n","\n","~~~~\n","sklearn.ensemble.VotingClassifier\n","~~~~ \n","\n","La documentación oficial la puede ver aquí: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n","\n","La sintaxis es la siguiente:  \n","\n","~~~\n","sklearn.ensemble.VotingClassifier(estimators, *, voting='hard', weights=None, n_jobs=None, flatten_transform=True, verbose=False)\n","~~~\n","\n","Los parámetros principales son: \n","\n","- **estimators**: lista de tuplas con el nombre de los modelos o estimadores previamente definidos, por ejemplo [('Regresión_Logística', rlog), ('k_Vecinos',knn) ...]  \n","- **voting**: hard o soft. Por defecto 'hard'. En el caso de empate sklearn elige el pronóstico del primer algoritmo en orden alfabético.\n","- **weights**: permite asignar un peso distinto a cada estimador \n","- **n_jobs=None** Cantidad de hilos dedicados a esta tarea. **En este caso pueden obtenerse muy buenos resultados al paralelizar ya que puede correr cada uno de los modelos en un hilo distinto, se sugiere setear en -1**."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:15:48.764448Z","start_time":"2020-10-30T01:15:46.686549Z"},"id":"tIFZVB_OpOiz"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn import linear_model\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"]},{"cell_type":"markdown","metadata":{"id":"47Et-kUVpOi0"},"source":["#### Los Datos"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:15:48.812933Z","start_time":"2020-10-30T01:15:48.766444Z"},"id":"q5AJDg3ypOi1","outputId":"15c73e90-6352-4a5a-c33a-eaab8040bf1f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fixed acidity</th>\n","      <th>volatile acidity</th>\n","      <th>citric acid</th>\n","      <th>residual sugar</th>\n","      <th>chlorides</th>\n","      <th>free sulfur dioxide</th>\n","      <th>total sulfur dioxide</th>\n","      <th>density</th>\n","      <th>pH</th>\n","      <th>sulphates</th>\n","      <th>alcohol</th>\n","      <th>quality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7.0</td>\n","      <td>0.27</td>\n","      <td>0.36</td>\n","      <td>20.7</td>\n","      <td>0.045</td>\n","      <td>45.0</td>\n","      <td>170.0</td>\n","      <td>1.00100</td>\n","      <td>3.00</td>\n","      <td>0.45</td>\n","      <td>8.8</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6.3</td>\n","      <td>0.30</td>\n","      <td>0.34</td>\n","      <td>1.6</td>\n","      <td>0.049</td>\n","      <td>14.0</td>\n","      <td>132.0</td>\n","      <td>0.99400</td>\n","      <td>3.30</td>\n","      <td>0.49</td>\n","      <td>9.5</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8.1</td>\n","      <td>0.28</td>\n","      <td>0.40</td>\n","      <td>6.9</td>\n","      <td>0.050</td>\n","      <td>30.0</td>\n","      <td>97.0</td>\n","      <td>0.99510</td>\n","      <td>3.26</td>\n","      <td>0.44</td>\n","      <td>10.1</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7.2</td>\n","      <td>0.23</td>\n","      <td>0.32</td>\n","      <td>8.5</td>\n","      <td>0.058</td>\n","      <td>47.0</td>\n","      <td>186.0</td>\n","      <td>0.99560</td>\n","      <td>3.19</td>\n","      <td>0.40</td>\n","      <td>9.9</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.2</td>\n","      <td>0.23</td>\n","      <td>0.32</td>\n","      <td>8.5</td>\n","      <td>0.058</td>\n","      <td>47.0</td>\n","      <td>186.0</td>\n","      <td>0.99560</td>\n","      <td>3.19</td>\n","      <td>0.40</td>\n","      <td>9.9</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4893</th>\n","      <td>6.2</td>\n","      <td>0.21</td>\n","      <td>0.29</td>\n","      <td>1.6</td>\n","      <td>0.039</td>\n","      <td>24.0</td>\n","      <td>92.0</td>\n","      <td>0.99114</td>\n","      <td>3.27</td>\n","      <td>0.50</td>\n","      <td>11.2</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4894</th>\n","      <td>6.6</td>\n","      <td>0.32</td>\n","      <td>0.36</td>\n","      <td>8.0</td>\n","      <td>0.047</td>\n","      <td>57.0</td>\n","      <td>168.0</td>\n","      <td>0.99490</td>\n","      <td>3.15</td>\n","      <td>0.46</td>\n","      <td>9.6</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4895</th>\n","      <td>6.5</td>\n","      <td>0.24</td>\n","      <td>0.19</td>\n","      <td>1.2</td>\n","      <td>0.041</td>\n","      <td>30.0</td>\n","      <td>111.0</td>\n","      <td>0.99254</td>\n","      <td>2.99</td>\n","      <td>0.46</td>\n","      <td>9.4</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4896</th>\n","      <td>5.5</td>\n","      <td>0.29</td>\n","      <td>0.30</td>\n","      <td>1.1</td>\n","      <td>0.022</td>\n","      <td>20.0</td>\n","      <td>110.0</td>\n","      <td>0.98869</td>\n","      <td>3.34</td>\n","      <td>0.38</td>\n","      <td>12.8</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>4897</th>\n","      <td>6.0</td>\n","      <td>0.21</td>\n","      <td>0.38</td>\n","      <td>0.8</td>\n","      <td>0.020</td>\n","      <td>22.0</td>\n","      <td>98.0</td>\n","      <td>0.98941</td>\n","      <td>3.26</td>\n","      <td>0.32</td>\n","      <td>11.8</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4898 rows × 12 columns</p>\n","</div>"],"text/plain":["      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n","0               7.0              0.27         0.36            20.7      0.045   \n","1               6.3              0.30         0.34             1.6      0.049   \n","2               8.1              0.28         0.40             6.9      0.050   \n","3               7.2              0.23         0.32             8.5      0.058   \n","4               7.2              0.23         0.32             8.5      0.058   \n","...             ...               ...          ...             ...        ...   \n","4893            6.2              0.21         0.29             1.6      0.039   \n","4894            6.6              0.32         0.36             8.0      0.047   \n","4895            6.5              0.24         0.19             1.2      0.041   \n","4896            5.5              0.29         0.30             1.1      0.022   \n","4897            6.0              0.21         0.38             0.8      0.020   \n","\n","      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n","0                    45.0                 170.0  1.00100  3.00       0.45   \n","1                    14.0                 132.0  0.99400  3.30       0.49   \n","2                    30.0                  97.0  0.99510  3.26       0.44   \n","3                    47.0                 186.0  0.99560  3.19       0.40   \n","4                    47.0                 186.0  0.99560  3.19       0.40   \n","...                   ...                   ...      ...   ...        ...   \n","4893                 24.0                  92.0  0.99114  3.27       0.50   \n","4894                 57.0                 168.0  0.99490  3.15       0.46   \n","4895                 30.0                 111.0  0.99254  2.99       0.46   \n","4896                 20.0                 110.0  0.98869  3.34       0.38   \n","4897                 22.0                  98.0  0.98941  3.26       0.32   \n","\n","      alcohol  quality  \n","0         8.8        6  \n","1         9.5        6  \n","2        10.1        6  \n","3         9.9        6  \n","4         9.9        6  \n","...       ...      ...  \n","4893     11.2        6  \n","4894      9.6        5  \n","4895      9.4        6  \n","4896     12.8        7  \n","4897     11.8        6  \n","\n","[4898 rows x 12 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df=pd.read_csv('data/winequality-white.csv', sep=';')\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:15:48.821907Z","start_time":"2020-10-30T01:15:48.815928Z"},"id":"hTFLVuzFpOi2"},"outputs":[],"source":["X=df.drop(axis=1,columns='quality')\n","y=df['quality']"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:15:48.833873Z","start_time":"2020-10-30T01:15:48.824896Z"},"id":"NlQCLQjYpOi2"},"outputs":[],"source":["X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=123)"]},{"cell_type":"markdown","metadata":{"id":"TVjm8Lh9pOi3"},"source":["#### Los Modelos\n","\n","Elijamos modelos que sean lo más distintos posible, por ejemplo:\n","\n","- Regresión Logística con Ridge\n","- kNN\n","- Árbol\n","- SVM"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-10-29T13:59:47.793056Z","start_time":"2020-10-29T13:59:47.789067Z"},"id":"yTgMscxvpOi3"},"source":["##### Regresión Logística + Ridge"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:15:48.840853Z","start_time":"2020-10-30T01:15:48.835868Z"},"id":"OdAM6NaXpOi3"},"outputs":[],"source":["ridge=linear_model.LogisticRegression(max_iter= 20000,penalty='l2',fit_intercept=True, random_state=123)"]},{"cell_type":"markdown","metadata":{"id":"o8onb3D3pOi3"},"source":["##### kNN"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:15:48.845840Z","start_time":"2020-10-30T01:15:48.842848Z"},"id":"9E6rCAbWpOi4"},"outputs":[],"source":["knn=KNeighborsClassifier()"]},{"cell_type":"markdown","metadata":{"id":"7NXjU6KXpOi4"},"source":["##### Árbol"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:15:48.851824Z","start_time":"2020-10-30T01:15:48.847835Z"},"id":"jYk84DokpOi4"},"outputs":[],"source":["tree=DecisionTreeClassifier(random_state=123)"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-10-29T15:40:17.944571Z","start_time":"2020-10-29T15:40:17.940621Z"},"id":"O5lrXdavpOi4"},"source":["##### SVM"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:15:48.861535Z","start_time":"2020-10-30T01:15:48.856549Z"},"id":"ZwtGb3aupOi5"},"outputs":[],"source":["svm=SVC( random_state=123)"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-10-29T15:43:45.973333Z","start_time":"2020-10-29T15:43:45.968349Z"},"id":"umbG4NHtpOi5"},"source":["##### Resultados individuales de Accuracy (la métrica por defecto para los clasificadores en sklearn)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:16:12.801677Z","start_time":"2020-10-30T01:15:48.864528Z"},"id":"JmM4cBtGpOi5","outputId":"1318c0b0-1727-47af-8159-3fc20e12414e"},"outputs":[{"name":"stdout","output_type":"stream","text":["AC:  0.560204081632653\n","AC:  0.49081632653061225\n","AC:  0.6020408163265306\n","AC:  0.4826530612244898\n"]}],"source":["modelos_lista=(ridge, knn, tree, svm)\n","\n","for modelo in modelos_lista:\n","    modelo.fit(X_train,y_train)\n","    AC=modelo.score(X_test,y_test)\n","    print(\"AC: \",AC)"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-10-29T14:05:36.948383Z","start_time":"2020-10-29T14:05:36.943398Z"},"id":"IRkIFBULpOi5"},"source":["#### VotingClassifier: La votación"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:18:30.883810Z","start_time":"2020-10-30T01:18:30.878821Z"},"id":"enk6eWNDpOi6"},"outputs":[],"source":["from sklearn.ensemble import VotingClassifier"]},{"cell_type":"markdown","metadata":{"id":"S1kJz-N5pOi6"},"source":["##### Creamos el VotingClassifier:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:18:30.913241Z","start_time":"2020-10-30T01:18:30.906299Z"},"id":"B7iqifzWpOi6"},"outputs":[],"source":["modelos=[('ridge',ridge),('knn',knn),('arbol',tree),('svm',svm)]\n","votacion=VotingClassifier(estimators=modelos,voting='hard',n_jobs=-1, weights=[2,1,3,1])"]},{"cell_type":"markdown","metadata":{"id":"8RBOUAvqpOi6"},"source":["##### Lo entrenamos con fit (como siempre ... gracias sklearn!)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:18:53.405562Z","start_time":"2020-10-30T01:18:30.935514Z"},"id":"Pko7WKctpOi6"},"outputs":[],"source":["votacion.fit(X_train, y_train);"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-10-29T15:46:38.380721Z","start_time":"2020-10-29T15:46:38.377730Z"},"id":"k5bhyVRopOi6"},"source":["##### Lo evaluamos"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:18:53.649909Z","start_time":"2020-10-30T01:18:53.407558Z"},"id":"Ik_uhWE7pOi7","outputId":"d45c00b4-aa6b-4582-96ab-f21b9dca5237"},"outputs":[{"name":"stdout","output_type":"stream","text":["AC_votacion:  0.6336734693877552\n"]}],"source":["AC_votacion=votacion.score(X_test,y_test)\n","print(\"AC_votacion: \",AC_votacion)"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-10-29T15:49:50.925318Z","start_time":"2020-10-29T15:49:50.922283Z"},"id":"qEWbzbaNpOi7"},"source":["### Conclusión: \n","\n","En este caso el resultado del Ensemble mejoró ligeramente los resultados individuales."]}],"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Tabla de Contenidos","title_sidebar":"Contenidos","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"172.225px"},"toc_section_display":true,"toc_window_display":true},"colab":{"name":"Sp05-01.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}