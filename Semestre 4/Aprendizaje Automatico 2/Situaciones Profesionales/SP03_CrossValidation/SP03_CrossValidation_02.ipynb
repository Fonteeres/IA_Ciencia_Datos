{"cells":[{"cell_type":"markdown","metadata":{"toc":true,"id":"1VnWVUkr7kDM"},"source":["<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n","<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Cross-Validation-para-Selección-de-Modelo-e-Hiperparámetros:---&quot;Separando-el-Test-Set&quot;\" data-toc-modified-id=\"Cross-Validation-para-Selección-de-Modelo-e-Hiperparámetros:---&quot;Separando-el-Test-Set&quot;-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Cross Validation para Selección de Modelo e Hiperparámetros:   \"Separando el Test Set\"</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fundamentos\" data-toc-modified-id=\"Fundamentos-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Fundamentos</a></span></li><li><span><a href=\"#Evaluación-del-modelo-elegido:\" data-toc-modified-id=\"Evaluación-del-modelo-elegido:-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Evaluación del modelo elegido:</a></span></li><li><span><a href=\"#Modelo-para-producción:\" data-toc-modified-id=\"Modelo-para-producción:-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Modelo para producción:</a></span></li><li><span><a href=\"#Pregunta-1:\" data-toc-modified-id=\"Pregunta-1:-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Pregunta 1:</a></span></li><li><span><a href=\"#Respuesta-1:\" data-toc-modified-id=\"Respuesta-1:-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Respuesta 1:</a></span></li></ul></li><li><span><a href=\"#Ejemplo-1:--Cross-Validation-para-Selección-de-Modelo-e-Hiperparámetros:---&quot;Separando-el-Test-Set&quot;-procedimiento-&quot;manual&quot;\" data-toc-modified-id=\"Ejemplo-1:--Cross-Validation-para-Selección-de-Modelo-e-Hiperparámetros:---&quot;Separando-el-Test-Set&quot;-procedimiento-&quot;manual&quot;-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Ejemplo 1:  Cross Validation para Selección de Modelo e Hiperparámetros:   \"Separando el Test Set\" procedimiento \"manual\"</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cargamos-los-datos-y-separamos-en-Train-y-Test-en-proporción-80/20-y-con-semilla-123\" data-toc-modified-id=\"Cargamos-los-datos-y-separamos-en-Train-y-Test-en-proporción-80/20-y-con-semilla-123-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Cargamos los datos y separamos en Train y Test en proporción 80/20 y con semilla 123</a></span></li><li><span><a href=\"#Modelo1:-Árbol\" data-toc-modified-id=\"Modelo1:-Árbol-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Modelo1: Árbol</a></span></li><li><span><a href=\"#Modelo2:-Regresión-Logística-+-Ridge\" data-toc-modified-id=\"Modelo2:-Regresión-Logística-+-Ridge-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Modelo2: Regresión Logística + Ridge</a></span></li><li><span><a href=\"#Selección-de-modelo-/-hiperparámetros:\" data-toc-modified-id=\"Selección-de-modelo-/-hiperparámetros:-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Selección de modelo / hiperparámetros:</a></span></li><li><span><a href=\"#Evaluación-del-Modelo-elegido:\" data-toc-modified-id=\"Evaluación-del-Modelo-elegido:-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Evaluación del Modelo elegido:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pregunta:\" data-toc-modified-id=\"Pregunta:-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Pregunta:</a></span></li><li><span><a href=\"#Respuesta:\" data-toc-modified-id=\"Respuesta:-2.5.2\"><span class=\"toc-item-num\">2.5.2&nbsp;&nbsp;</span>Respuesta:</a></span></li></ul></li><li><span><a href=\"#Modelo-para-Producción:\" data-toc-modified-id=\"Modelo-para-Producción:-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Modelo para Producción:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creamos-el-modelo-y-lo-entrenamos-con-.fit\" data-toc-modified-id=\"Creamos-el-modelo-y-lo-entrenamos-con-.fit-2.6.1\"><span class=\"toc-item-num\">2.6.1&nbsp;&nbsp;</span>Creamos el modelo y lo entrenamos con .fit</a></span></li><li><span><a href=\"#.predict-para-pronosticar\" data-toc-modified-id=\".predict-para-pronosticar-2.6.2\"><span class=\"toc-item-num\">2.6.2&nbsp;&nbsp;</span>.predict para pronosticar</a></span></li><li><span><a href=\"#Guardamos-el-modelo-para-uso-posterior-con-pickle:\" data-toc-modified-id=\"Guardamos-el-modelo-para-uso-posterior-con-pickle:-2.6.3\"><span class=\"toc-item-num\">2.6.3&nbsp;&nbsp;</span>Guardamos el modelo para uso posterior con pickle:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Uso-posterior-del-modelo:\" data-toc-modified-id=\"Uso-posterior-del-modelo:-2.6.3.1\"><span class=\"toc-item-num\">2.6.3.1&nbsp;&nbsp;</span>Uso posterior del modelo:</a></span></li></ul></li></ul></li></ul></li></ul></div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NFteFfEm7kDP"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"0_MUdUwA7kDP"},"source":["# Cross Validation para Selección de Modelo e Hiperparámetros"]},{"cell_type":"markdown","metadata":{"id":"OmfWSOH47kDQ"},"source":["Con anterioridad hemos visto cómo usar CV para evaluar un modelo ya definido, ahora veremos cómo aplicar CV  para comparar los distintos modelos o distintos valores de hiperparámetros a la hora de hacer Selección de Modelo para elegir luego el que mejor funcione.  \n","\n","> El tema central que no hay que perder de vista es que cuando debemos evaluar el modelo final obtenido, debe ser evaluado en observaciones que no hayamos utilizado para seleccionar el modelo.   \n","\n","Mostraremos 2 formas de hacerlo, si bien no reciben formalmente nombres en la literatura, las llamaremos:  \n","\n","- **Cross Validation \"Separando el Test Set\"**\n","    - \"Manual\"\n","    - Usando GridSearchCV (más automatizado}\n","- **Cross Validation \"Anidado\"**\n"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-09-23T16:14:16.067855Z","start_time":"2020-09-23T16:14:16.063878Z"},"id":"Sd8A5QKZ7kDQ"},"source":["## Cross Validation para Selección de Modelo e Hiperparámetros:   \"Separando el Test Set\"\n","### Fundamentos"]},{"cell_type":"markdown","metadata":{"id":"YZvzkTop7kDQ"},"source":["En este caso, apenas comenzamos separaremos  en Train Set y Test Set como hacíamos antes.   \n","\n","- El Test Set **no será usado** durante el proceso de selección de modelo o de hiperparámetros.\n"]},{"cell_type":"markdown","metadata":{"id":"9PblnP9A7kDR"},"source":["![Seleccion%20Modelo%2001.svg](attachment:Seleccion%20Modelo%2001.svg)"]},{"cell_type":"markdown","metadata":{"id":"6I9TXsp57kDR"},"source":["Ahora **para cada modelo que queremos probar y/o para cada valor de su hiperparámetro** correremos k fold CV **dentro del Train Set**, de esta manera para cada combinación de modelo / hiperparámetro obtendremos el resultado de la métrica de evaluación (por ejemplo AC o RMSE) con más confianza que antes:"]},{"cell_type":"markdown","metadata":{"id":"wkKegzBY7kDS"},"source":["![Seleccion%20Modelo%2002.svg](attachment:Seleccion%20Modelo%2002.svg)"]},{"cell_type":"markdown","metadata":{"id":"MhcEuJ2M7kDS"},"source":["Como podemos ver, muy parecido a lo que hacíamos antes, excepto que ahora en vez de entrenar cada modelo / hiper en un solo ValTrain y evaluarlo en un solo ValTest, ahora le aplicamos CV y lo hacemos k veces, luego promediamos los resultados para cada modelo / hiper y finalmente elegiríamos el modelo / hiper que mejores resultados obtuvo.    \n","Eso sí, el esfuerzo computacional se multiplicó por k."]},{"cell_type":"markdown","metadata":{"id":"EwgOB6pI7kDS"},"source":["### Evaluación del modelo elegido:\n","\n","\n","Una vez elegido el mejor modelo / hiperparámetro lo entrenaremos en el Train Set y lo **evaluarermos en el Test Set que habíamos separado al inicio**, como hacíamos antes.   \n","\n","- Lamentablemente como haremos una única evaluación, no obtendremos el intervalo de confianza."]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-09-23T17:15:39.184426Z","start_time":"2020-09-23T17:15:39.180440Z"},"id":"Gul3z2F37kDT"},"source":["### Modelo para producción:  \n","\n","Como siempre: Entrenaremos en el todo el DataSet y asumiremos el valor de la evaluación anterior."]},{"cell_type":"markdown","metadata":{"id":"NmA7gngI7kDT"},"source":["### Pregunta 1:  \n","\n","Ésta es pregunta **fundamental**:  \n","Por qué una vez elegido el mejor modelo, no lo evaluamos aplicando k fold Cross Validation sobre todo el DataSet, para así obtener varias métricas que podríamos promediar y dar el intervalo de confianza?"]},{"cell_type":"markdown","metadata":{"id":"X4-FYrBq7kDT"},"source":["### Respuesta 1:\n","\n","Observe que si hiciéramos eso en cada uno de los Test Sets que se generarían en cada fold participarían observaciones que usamos para entrenar anteriormente en el proceso de selección de modelo, posiblemente habrá tambien desconocidas, que formaban parte del TestSet que habíamos separado, pero igual habríamos sesgado los resultados de la evaluación con **sesgo optimista**, es decir daría mejor que la realidad."]},{"cell_type":"markdown","metadata":{"id":"lqbzm1fa7kDT"},"source":["## Ejemplo 1:  Cross Validation para Selección de Modelo e Hiperparámetros:   \"Separando el Test Set\" procedimiento \"manual\"\n","\n","Supongamos que tenemos los mismos datos  del ejemplo anterior, 'data/datos1.csv'. Ahora queremos hacer selección de modelo / hiperparámetros comparando: \n","- Árbol con profundidades de 1 a 4  \n","- Regresión Logística  + Ridge con valores de regularización [1e-6,1e-5,1e-4,0.001,0.01,0.1,1,10]\n","\n","- Cuando usemos CV, los haremos con **5 folds**.\n","- Sólo evaluaremos con Accuracy\n","\n","En este ejemplo vamos a correr cada modelo por separado y luego compararemos sus resultados para facilitar la comprensión."]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-09-23T17:38:40.661300Z","start_time":"2020-09-23T17:38:40.657310Z"},"id":"Tda_Vzg07kDU"},"source":["### Cargamos los datos y separamos en Train y Test en proporción 80/20 y con semilla 123"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T11:03:53.813487Z","start_time":"2020-09-24T11:03:53.366656Z"},"id":"uU0dbCsW7kDU","outputId":"59c1b3f2-563d-4187-8a82-a92c9d116ea0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x1</th>\n","      <th>x2</th>\n","      <th>x3</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.674774</td>\n","      <td>-1.368211</td>\n","      <td>-0.174910</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.721351</td>\n","      <td>-3.060436</td>\n","      <td>-3.259069</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-2.270269</td>\n","      <td>-0.196512</td>\n","      <td>1.448112</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.989482</td>\n","      <td>-0.553864</td>\n","      <td>0.414766</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.043243</td>\n","      <td>0.690214</td>\n","      <td>-0.388195</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         x1        x2        x3  y\n","0 -0.674774 -1.368211 -0.174910  0\n","1  2.721351 -3.060436 -3.259069  1\n","2 -2.270269 -0.196512  1.448112  0\n","3 -0.989482 -0.553864  0.414766  0\n","4  1.043243  0.690214 -0.388195  1"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","df=pd.read_csv('data/datos1.csv')\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"keppHRRs7kDV"},"source":["Separamos X e y:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T11:03:53.842384Z","start_time":"2020-09-24T11:03:53.815455Z"},"id":"hLdtoFl27kDV"},"outputs":[],"source":["X=df.drop(axis=1,columns='y')     # quitamos la columna y porque es la variable a pronosticar\n","y=df['y']                         # variable a pronosticar."]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-09-23T17:41:47.360040Z","start_time":"2020-09-23T17:41:47.354055Z"},"id":"Lp44sK3r7kDV"},"source":["Ahora separamos en Train y Test:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T11:03:54.311183Z","start_time":"2020-09-24T11:03:53.845376Z"},"id":"8-4fDV7o7kDV"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=20,random_state=123)"]},{"cell_type":"markdown","metadata":{"id":"aPmrF1Oq7kDV"},"source":["> Recordemos que en este procedimiento **separaremos el Test Set (X_test e y_test) hasta el final, para evaluar el modelo elegido**."]},{"cell_type":"markdown","metadata":{"id":"Cc85QIzX7kDW"},"source":["De las dos alternativas que vimos para efectuar CV, cross_val_score y cross_validate, vamos a utilizar la segunda aunque cualquiera hubiera servido."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T11:03:54.317114Z","start_time":"2020-09-24T11:03:54.313124Z"},"id":"9t4nLeaz7kDW"},"outputs":[],"source":["from sklearn.model_selection import cross_validate"]},{"cell_type":"markdown","metadata":{"id":"QkbbYYXK7kDW"},"source":["### Modelo1: Árbol\n","\n","Como queremos probar para varias profundidades de árbol, vamos a armar un for.  Llamemos p a las distintas profundidades que queremos probar que eran [1,2,34], nos quedaría algo como lo siguiente:  \n","\n","~~~  \n","for p in [1,2,3,4]:\n","            arbol=DecisionTreeClassifier(max_depth=p)\n","~~~ \n","\n","Para cada valor de profundidad, crearíamos el arbol.   \n","Ahora queremos aplicarle CV (mediante cross_validate) para cada uno de estos valores del hiperparámetro p.   \n","\n","**No perdamos de vista que a cross_validate le pasaremos el Train Set( X_train e y_train)**\n","\n","~~~ \n","for p in [1,2,3,4]:\n","            arbol=DecisionTreeClassifier(max_depth=p, random_state=123)\n","            scores_arbol = cross_validate(arbol, X_train, y_train, cv=5, scoring=['accuracy'])\n","~~~ \n","\n","cross_validate creará automáticamente los 5 folds dividiendo al Train Set en lo solemos llamar Xval_train e yval_train; entrenará en el Xval_train y evaluará en el yval_test. Ahora recordemos que en scores_arbol['test_accuracy'] tendremos 5 valores de Accuracy, uno por cada fold y que debemos promediar estos valores para calcular AC en el fold, además podemos calcular el desvío standard para luego indicar el intervalo de confianza.\n","\n","~~~\n","for p in [1,2,3,4]:\n","            arbol=DecisionTreeClassifier(max_depth=p)\n","            scores_arbol = cross_validate(arbol, X_train, y_train, cv=5, scoring=['accuracy'])\n","            AC=scores_arbol['test_accuracy'].mean()\n","            desvio=scores_arbol['test_accuracy'].std()\n","~~~\n"," Por último agreguemos un simple print para mostrar el AC +- 2 desvíos para cada valor de profundidad p del árbol:\n"," \n"," ~~~\n","print(\"Modelo: Árbol\")\n","for p in [1,2,3,4]:\n","            arbol=DecisionTreeClassifier(max_depth=p)\n","            scores_arbol = cross_validate(arbol,X_train, y_train, cv=5, scoring=['accuracy'])\n","            AC=scores_arbol['test_accuracy'].mean()\n","            desvio=scores_arbol['test_accuracy'].std()\n","            print(\"---------------------------------------------------------\")\n","            print(\"Profundidad: \", p, \"AC= \", AC, \" +/- \", 2*desvio, ' (95%)')\n","            print(\"---------------------------------------------------------\")\n"," \n"," ~~~\n"," \n"," Hagámoslo:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T14:06:38.231460Z","start_time":"2020-09-24T14:06:38.148647Z"},"id":"3w6FfqbS7kDW","outputId":"585a7f80-931d-479d-e830-ffc7438061a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Modelo: Árbol\n","---------------------------------------------------------\n","Profundidad:  1 AC=  0.7666666666666667  +/-  0.16329931618554527  (95%)\n","---------------------------------------------------------\n","---------------------------------------------------------\n","Profundidad:  2 AC=  0.8333333333333334  +/-  0.21081851067789198  (95%)\n","---------------------------------------------------------\n","---------------------------------------------------------\n","Profundidad:  3 AC=  0.7666666666666667  +/-  0.33993463423951903  (95%)\n","---------------------------------------------------------\n","---------------------------------------------------------\n","Profundidad:  4 AC=  0.7666666666666667  +/-  0.33993463423951903  (95%)\n","---------------------------------------------------------\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","\n","print(\"Modelo: Árbol\")\n","for p in [1,2,3,4]:\n","            arbol=DecisionTreeClassifier(max_depth=p, random_state=123)\n","            scores_arbol = cross_validate(arbol, X_train, y_train, cv=5, scoring=['accuracy'])\n","            AC=scores_arbol['test_accuracy'].mean()\n","            desvio=scores_arbol['test_accuracy'].std()\n","            print(\"---------------------------------------------------------\")\n","            print(\"Profundidad: \", p, \"AC= \", AC, \" +/- \", 2*desvio, ' (95%)')\n","            print(\"---------------------------------------------------------\")\n","            "]},{"cell_type":"markdown","metadata":{"id":"xjWih0d37kDW"},"source":["Observamos que el mejor árbol lo obtuvimos con profundidad p=2."]},{"cell_type":"markdown","metadata":{"id":"g7sascMt7kDX"},"source":["**Nota:** Sklearn tiene una herramienta hasta para evitarnos el for que hemos hecho, se denomina GridSearchCV ... pero la veremos más adelante."]},{"cell_type":"markdown","metadata":{"id":"F_XtvISh7kDX"},"source":["### Modelo2: Regresión Logística + Ridge  \n","\n","La estructura del proceso será la misma que antes, sólo que ahora crearemos un modelo de Regresión Logística y que el hiperparámetro serán los valores para C, podríamos probar con [1e-6,1e-5,1e-4,0.001,0.01,0.1,1,10].   \n","\n","Hagámoslo:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T14:06:05.459030Z","start_time":"2020-09-24T14:06:05.157836Z"},"id":"nPfc--ID7kDX","outputId":"7b0c9665-8034-4c61-eb9d-e004a9922d29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Modelo: Regresión Logística con Regularización Ridge\n","---------------------------------------------------------\n","Regularización C:  1e-06 AC=  0.5666666666666667  +/-  0.2666666666666667  (95%)\n","---------------------------------------------------------\n","---------------------------------------------------------\n","Regularización C:  1e-05 AC=  0.5666666666666667  +/-  0.2666666666666667  (95%)\n","---------------------------------------------------------\n","---------------------------------------------------------\n","Regularización C:  0.0001 AC=  0.5666666666666667  +/-  0.2666666666666667  (95%)\n","---------------------------------------------------------\n","---------------------------------------------------------\n","Regularización C:  0.001 AC=  0.5666666666666667  +/-  0.2666666666666667  (95%)\n","---------------------------------------------------------\n","---------------------------------------------------------\n","Regularización C:  0.01 AC=  0.7  +/-  0.24944382578492946  (95%)\n","---------------------------------------------------------\n","---------------------------------------------------------\n","Regularización C:  0.1 AC=  0.9  +/-  0.16329931618554516  (95%)\n","---------------------------------------------------------\n","---------------------------------------------------------\n","Regularización C:  1 AC=  0.9  +/-  0.16329931618554516  (95%)\n","---------------------------------------------------------\n","---------------------------------------------------------\n","Regularización C:  10 AC=  0.9  +/-  0.16329931618554516  (95%)\n","---------------------------------------------------------\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","\n","print(\"Modelo: Regresión Logística con Regularización Ridge\")\n","\n","for c in [1e-6,1e-5,1e-4,0.001,0.01,0.1,1,10]:\n","    Log_Ridge=LogisticRegression(penalty='l2', C=c, max_iter=10000, tol=0.0001)  \n","    # no usamos multi_class='ovr' porque es un problema de sólo 2 clases.\n","    scores_Log_Ridge = cross_validate(Log_Ridge, X_train, y_train, cv=5, scoring=['accuracy'])\n","    AC=scores_Log_Ridge['test_accuracy'].mean()\n","    desvio=scores_Log_Ridge['test_accuracy'].std()\n","    print(\"---------------------------------------------------------\")\n","    print(\"Regularización C: \", c, \"AC= \", AC, \" +/- \", 2*desvio, ' (95%)')\n","    print(\"---------------------------------------------------------\")\n","    \n","    "]},{"cell_type":"markdown","metadata":{"id":"jO72S1_v7kDX"},"source":["Observamos que podríamos considerar que el mejor hiperparámetro es con Regularización C=0.1."]},{"cell_type":"markdown","metadata":{"id":"At2icrez7kDX"},"source":["### Selección de modelo / hiperparámetros:"]},{"cell_type":"markdown","metadata":{"id":"jRin2DXE7kDX"},"source":["Ahora deberíamos elegir cuál fue el mejor modelo / hiperparámetro que nos quedó. En este caso, nos quedó que tanto el mejor árbol como el mejor RL + Ridge dan exactamente los mismos resultados, así que nos decidimos por: **Regresión Logística + Ridge con C=0.1.**"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-09-23T22:58:41.759124Z","start_time":"2020-09-23T22:58:41.756119Z"},"id":"SmYlFO1y7kDX"},"source":["### Evaluación del Modelo elegido:"]},{"cell_type":"markdown","metadata":{"id":"WgUDyZnd7kDX"},"source":["Los pasos anteriores nos han servido para seleccionar cuál es el mejor modelo y sus hiperparámetros.   \n","Una vez hecho ésto, ahora queremos **evaluar el modelo elegido** para tener una idea sobre qué tan bien pronosticará sobre observaciones no vistas. Para ello tenemos guardado y sin usar al Test Set.   \n","\n","Deberemos crear el modelo de **Regresión Logística con regularización Ridge con C=0.1**, lo entrenaremos en todo el Train Set y lo evaluaremos en el Test_Set calculando el AC."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T11:03:54.678152Z","start_time":"2020-09-24T11:03:54.660196Z"},"id":"Ua2Stz8q7kDY","outputId":"0abf301b-95f3-4fff-9caf-98e53043e581"},"outputs":[{"name":"stdout","output_type":"stream","text":["AC=  1.0\n","F1=  1.0\n","Matriz de Confusión: \n"]},{"data":{"text/plain":["array([[ 9,  0],\n","       [ 0, 11]], dtype=int64)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.metrics import f1_score, confusion_matrix, classification_report\n","modelo_elegido=LogisticRegression(penalty='l2', C=0.1, max_iter=10000, tol=0.0001) # observe el valor de C\n","modelo_elegido.fit(X_train, y_train)  # Entrenamos con .fit\n","AC=modelo_elegido.score(X_test, y_test)  # calculamos Accuracy\n","\n","# Podríamos calcular también f1\n","y_pred=modelo_elegido.predict(X_test)          # pronosticamos los valores de y \n","f1=f1_score(y_test,y_pred, average=\"micro\")    # evaluamos F1\n","\n","# Si fuera pertinente, como es un problema de Clasificación, podriamos presentar la Confusion Matrix\n","matriz_confusion=confusion_matrix(y_test,y_pred,labels=y.unique())\n","\n","# Ahora imprimamos todo:\n","\n","print(\"AC= \", AC)\n","print(\"F1= \", f1)\n","print(\"Matriz de Confusión: \")  \n","matriz_confusion"]},{"cell_type":"markdown","metadata":{"id":"vSz_vrLK7kDY"},"source":["Qué hermoso resultado!  \n","**Sólo podemos lamentar que no presentamos los valores de AC o F1 con sus correspondientes intervalos de confianza.** \n"]},{"cell_type":"markdown","metadata":{"id":"7uhN_FTZ7kDY"},"source":["#### Pregunta:  \n","\n","El modelo_elegido es el que utilizaremos en producción? "]},{"cell_type":"markdown","metadata":{"id":"b2TqN1757kDY"},"source":["#### Respuesta: \n","\n","No. El modelo para producción lo entrenaremos en todo el DataSet Original y ya no lo evaluaremos (no tendríamos con qué), pero presentaremos como AC esperado el que acabamos de calcular."]},{"cell_type":"markdown","metadata":{"id":"VB6urXYi7kDY"},"source":["### Modelo para Producción:\n","\n","Si respondió bien la pregunta anterior, ya sabe qué haremos ahora: entrenaremos el modelo_elegido (con los hiperparámetros ya determinados) en todo el DataSet Original, y lo guardaremos para usarlo posteriormente."]},{"cell_type":"markdown","metadata":{"id":"d36q3_YJ7kDY"},"source":["#### Creamos el modelo y lo entrenamos con .fit"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T11:03:54.695102Z","start_time":"2020-09-24T11:03:54.682139Z"},"id":"F_AnVuQ67kDY","outputId":"3a6d0f68-9e83-4661-cbac-662cd0719de1"},"outputs":[{"data":{"text/plain":["LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["modelo_produccion=LogisticRegression(penalty='l2', C=0.1, max_iter=10000, tol=0.0001) # observe el valor de C\n","modelo_produccion.fit(X, y)  # Entrenamos con .fit"]},{"cell_type":"markdown","metadata":{"id":"cmRXyosV7kDZ"},"source":["Ahora tenemos el modelo listo para recibir nuevas observaciones a las que debemos pronosticar su valor de y!  \n","\n","Para poder pronosticar nos deben dar un valor para cada una de las variables X."]},{"cell_type":"markdown","metadata":{"id":"GmAyM-4s7kDZ"},"source":["#### .predict para pronosticar\n","Supongamos que quisiéramos pronosticar el valor de y para los valores de x1=1, x2=1.5, x3=0.87 de una nueva observación:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T11:03:54.723031Z","start_time":"2020-09-24T11:03:54.716049Z"},"id":"BAs18LXa7kDZ","outputId":"774fe464-be37-44fa-ddea-87c85c8be692"},"outputs":[{"data":{"text/plain":["array([1], dtype=int64)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["modelo_produccion.predict([[1,1.5,0.87]])"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-09-24T00:02:55.755756Z","start_time":"2020-09-24T00:02:55.750733Z"},"id":"JzzFlbCv7kDZ"},"source":["También podríamos efectuar varios pronósticos juntos, siempre respetando la estructura de los datos originales. Por ejemplo supongamos que las nuevas observaciones estuvieran en el df_nuevo:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T11:03:54.739983Z","start_time":"2020-09-24T11:03:54.726021Z"},"id":"OQejxlSX7kDZ","outputId":"2a0b9b9e-f4d0-4cf4-e26e-53495ec6f90a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x1</th>\n","      <th>x1</th>\n","      <th>x3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.5</td>\n","      <td>0.5</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>-3.1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    x1   x1   x3\n","0 -0.5  0.5  2.0\n","1  2.0  0.0 -3.1\n","2 -1.0  1.0  1.0"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df_nuevo=pd.DataFrame([[-0.5,0.5,2],[2,0,-3.1],[-1,1,1]], columns=['x1','x1','x3'])\n","df_nuevo"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T11:03:54.749958Z","start_time":"2020-09-24T11:03:54.742976Z"},"id":"NOBaKEal7kDZ","outputId":"792a76d8-d293-4eed-e829-150e0233f5c3"},"outputs":[{"data":{"text/plain":["array([0, 1, 0], dtype=int64)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["modelo_produccion.predict(df_nuevo)"]},{"cell_type":"markdown","metadata":{"id":"BHijFlFH7kDZ"},"source":["#### Guardamos el modelo para uso posterior con pickle:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T11:03:54.705083Z","start_time":"2020-09-24T11:03:54.698095Z"},"id":"8r5Dvk0t7kDa"},"outputs":[],"source":["import pickle\n","# Comenté las siguientes líneas porque sino cada vez que corro este archivo, guardaría.\n","\n","# archivo = 'data/modelo_produccion.sav'\n","# pickle.dump(modelo_produccion, open(archivo, 'wb'))"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-09-23T23:56:44.291066Z","start_time":"2020-09-23T23:56:44.287077Z"},"id":"4vDeNnLw7kDa"},"source":["##### Uso posterior del modelo:"]},{"cell_type":"markdown","metadata":{"id":"1r5iIfK17kDa"},"source":["Cuando a posteriori querramos utilizar el modelo entrenado, listo para usar,  tendremos que cargarlo también con pickle de la siguiente forma:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T11:03:54.713056Z","start_time":"2020-09-24T11:03:54.708069Z"},"id":"prNyJfyR7kDa"},"outputs":[],"source":["archivo = 'data/modelo_produccion.sav'\n","modelo_cargado=pickle.load(open(archivo, 'rb'))"]},{"cell_type":"markdown","metadata":{"id":"v80fA1zS7kDa"},"source":["para estar seguros que anda igual que modelo_produccion:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-24T17:11:47.294557Z","start_time":"2020-09-24T17:11:47.286544Z"},"id":"fJSJ2ng97kDa","outputId":"8d128112-8d7f-4dab-cfbb-66b25f7d24db"},"outputs":[{"data":{"text/plain":["array([0, 1, 0], dtype=int64)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["modelo_cargado.predict(df_nuevo)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xf4mCOf97kDa"},"outputs":[],"source":[""]}],"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Tabla de Contenidos","title_sidebar":"Contenidos","toc_cell":true,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"294px"},"toc_section_display":true,"toc_window_display":true},"colab":{"name":"SP03_CrossValidation_02.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}